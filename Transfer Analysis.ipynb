{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d175c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Define the data directory\n",
    "test_dir = '../dataset/DevanagariHandwrittenCharacterDataset/test'\n",
    "train_dir = '../dataset/DevanagariHandwrittenCharacterDataset/train'\n",
    "\n",
    "# Define the transformation to be applied to each image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "testset = ImageFolder(test_dir, transform=transform)\n",
    "trainset = ImageFolder(train_dir, transform=transform)\n",
    "\n",
    "# Create a dataloader\n",
    "batch_size = 64\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7aa3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([28, 28, 1])\n",
      "tensor(8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get iterator object\n",
    "data_iter = iter(testloader)\n",
    "\n",
    "# Get a batch of data\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Get a single image\n",
    "single_image = images[0]\n",
    "\n",
    "print(single_image.shape)\n",
    "\n",
    "newimg = torch.permute(single_image, (1,2,0))\n",
    "\n",
    "print(newimg.shape)\n",
    "\n",
    "plt.imshow(newimg, cmap=\"gray\")\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c8f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e5b5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Conv2d: 1-1                            (320)\n",
       "├─Conv2d: 1-2                            18,496\n",
       "├─Dropout2d: 1-3                         --\n",
       "├─Dropout2d: 1-4                         --\n",
       "├─Linear: 1-5                            1,179,776\n",
       "├─Linear: 1-6                            1,290\n",
       "=================================================================\n",
       "Total params: 1,199,882\n",
       "Trainable params: 1,199,562\n",
       "Non-trainable params: 320\n",
       "================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = Net()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('mnist_model_99_30.pt'))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.048, momentum=0.5)\n",
    "\n",
    "for name, weight in model.named_parameters():\n",
    "    print(name)\n",
    "    if((\"fc\" in name) or (\"conv2\" in name)):\n",
    "        weight.requires_grad = True\n",
    "    else:\n",
    "        weight.requires_grad = False\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71c79a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 9.7117, Test Accuracy: 25.17%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test_correct += (predicted == target).sum().item()\n",
    "test_loss /= len(testloader.dataset)\n",
    "test_accuracy = 100.0 * test_correct / len(testloader.dataset)\n",
    "print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49723c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de2b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5f130ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.5940, Training Accuracy: 83.10%\n",
      "Epoch: 2, Training Loss: 0.1702, Training Accuracy: 94.92%\n",
      "Epoch: 3, Training Loss: 0.1098, Training Accuracy: 96.53%\n",
      "Epoch: 4, Training Loss: 0.0835, Training Accuracy: 97.44%\n",
      "Epoch: 5, Training Loss: 0.0686, Training Accuracy: 98.04%\n",
      "Epoch: 6, Training Loss: 0.0557, Training Accuracy: 98.14%\n",
      "Epoch: 7, Training Loss: 0.0461, Training Accuracy: 98.55%\n",
      "Epoch: 8, Training Loss: 0.0435, Training Accuracy: 98.59%\n",
      "Epoch: 9, Training Loss: 0.0365, Training Accuracy: 98.84%\n",
      "Epoch: 10, Training Loss: 0.0333, Training Accuracy: 99.01%\n",
      "Epoch: 11, Training Loss: 0.0266, Training Accuracy: 99.17%\n",
      "Epoch: 12, Training Loss: 0.0276, Training Accuracy: 99.16%\n",
      "Epoch: 13, Training Loss: 0.0259, Training Accuracy: 99.13%\n",
      "Epoch: 14, Training Loss: 0.0247, Training Accuracy: 99.29%\n",
      "Epoch: 15, Training Loss: 0.0214, Training Accuracy: 99.35%\n",
      "Epoch: 16, Training Loss: 0.0236, Training Accuracy: 99.29%\n",
      "Epoch: 17, Training Loss: 0.0196, Training Accuracy: 99.42%\n",
      "Epoch: 18, Training Loss: 0.0176, Training Accuracy: 99.46%\n",
      "Epoch: 19, Training Loss: 0.0169, Training Accuracy: 99.44%\n",
      "Epoch: 20, Training Loss: 0.0156, Training Accuracy: 99.54%\n",
      "Epoch: 21, Training Loss: 0.0166, Training Accuracy: 99.46%\n",
      "Epoch: 22, Training Loss: 0.0143, Training Accuracy: 99.52%\n",
      "Epoch: 23, Training Loss: 0.0149, Training Accuracy: 99.52%\n",
      "Epoch: 24, Training Loss: 0.0131, Training Accuracy: 99.52%\n",
      "Epoch: 25, Training Loss: 0.0132, Training Accuracy: 99.60%\n",
      "Epoch: 26, Training Loss: 0.0123, Training Accuracy: 99.60%\n",
      "Epoch: 27, Training Loss: 0.0122, Training Accuracy: 99.58%\n",
      "Epoch: 28, Training Loss: 0.0099, Training Accuracy: 99.68%\n",
      "Epoch: 29, Training Loss: 0.0095, Training Accuracy: 99.69%\n",
      "Epoch: 30, Training Loss: 0.0113, Training Accuracy: 99.61%\n",
      "Best Training Accuracy: 99.69411764705882 at Epoch: 29\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 30\n",
    "Best_Train = -1\n",
    "Best_Epoch = -1\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    model.train()\n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_correct += (predicted == target).sum().item()\n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    train_accuracy = 100.0 * train_correct / len(trainloader.dataset)\n",
    "    if(train_accuracy>Best_Train):\n",
    "        Best_Train = train_accuracy\n",
    "        Best_Epoch = epoch+1\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Training Accuracy: {:.2f}%'.format(\n",
    "        epoch+1, train_loss, train_accuracy))\n",
    "\n",
    "print(f\"Best Training Accuracy: {Best_Train} at Epoch: {Best_Epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "138dab0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0211, Test Accuracy: 99.57%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.to(device)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        test_correct += (predicted == target).sum().item()\n",
    "test_loss /= len(testloader.dataset)\n",
    "test_accuracy = 100.0 * test_correct / len(testloader.dataset)\n",
    "print('Test Loss: {:.4f}, Test Accuracy: {:.2f}%'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05a0ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c15356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"devanagiri_weights_99_67\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c37ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9cf63c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
